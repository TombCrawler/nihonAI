{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "198QQXkVVb-tQLnEbzU1rW_Z_xncLfWR7",
      "authorship_tag": "ABX9TyO3aXWlXgrkcyi8gayXbT/1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TombCrawler/nihonAI/blob/main/Nov1stMiniGen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nov１st 教授emailより：簡単で構いませんので、メロディデータに対して、\n",
        "数個の音符列を入力すると、その次の音符を予測する\n",
        "というモデルをTensorFlowで作る"
      ],
      "metadata": {
        "id": "PBmlXfcjR2Un"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yb4Xw_GNRrSc"
      },
      "outputs": [],
      "source": [
        "!pip install midi2audio\n",
        "!apt install fluidsynth\n",
        "!pip install pretty_midi\n",
        "!pip install mido\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import os\n",
        "import glob\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from mpl_toolkits.mplot3d.axes3d import Axes3D\n",
        "\n",
        "import pretty_midi\n",
        "import IPython.display as ipd\n",
        "from midi2audio import FluidSynth\n",
        "from music21 import *\n",
        "\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "import mido\n",
        "from mido import MidiFile, MidiTrack, Message"
      ],
      "metadata": {
        "id": "Jh6F2ETiSSEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UnsupportedMidiFileException(Exception):\n",
        "  \"Unsupported MIDI File\""
      ],
      "metadata": {
        "id": "8Jf4KnG-nUfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pianoroll(midi, nn_from, nn_thru, seqlen, tempo):\n",
        "  pianoroll = midi.get_piano_roll(fs=2*tempo/60)\n",
        "  if pianoroll.shape[1] < seqlen:\n",
        "    raise UnsupportedMidiFileException\n",
        "  pianoroll = pianoroll[nn_from:nn_thru, 0:seqlen]\n",
        "  pianoroll = np.heaviside(pianoroll, 0)\n",
        "  return np.transpose(pianoroll)"
      ],
      "metadata": {
        "id": "j1Erq4mroDdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add rest nodes to the binary piano roll matrix to make the one-hot representation function\n",
        "\n",
        "# add rest nodes\n",
        "def add_rest_nodes(pianoroll):\n",
        "  # make a \"rest node series\"\n",
        "  # If all the elemets are zero, the rest node says 1, else 0\n",
        "  rests = 1 - np.sum(pianoroll, axis=1)\n",
        "  # Make the \"rest node series\" a 2D array and treat it as a Matrix\n",
        "  rests = np.expand_dims(rests, 1)\n",
        "  # Concatenate the binary pianoroll matrix and the rest node series matrix and return it\n",
        "  return np.concatenate([pianoroll, rests], axis=1)"
      ],
      "metadata": {
        "id": "YHeYzMV0oV4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ciZCwV9mrEHK"
      },
      "outputs": [],
      "source": [
        "def read_midi(filename, sop_alto, seqlen):\n",
        "  # read midi file\n",
        "  midi = pretty_midi.PrettyMIDI(filename)\n",
        "\n",
        "  # An Exception error is thrown if there is a modulation(key change)\n",
        "  if len(midi.key_signature_changes) !=1:\n",
        "    raise UnsupportedMidiFileException\n",
        "\n",
        "  # Modulate the given key to C major or C minor\n",
        "  key_number = midi.key_signature_changes[0].key_number\n",
        "  # transpose_to_c(midi, key_number)\n",
        "\n",
        "  # Get Major key(keynode=0) or Minor key(keynode=1)\n",
        "  keymode = np.array([int(key_number / 12)])\n",
        "\n",
        "  # The Exception error thrown when tempo changes\n",
        "  tempo_time, tempo = midi.get_tempo_changes()\n",
        "  if len(tempo) != 1:\n",
        "    raise UnsupportedMidiFileException\n",
        "  if sop_alto:\n",
        "    # The exception thrown if there are less than 2 parts\n",
        "    if len(midi.instruments) < 2:\n",
        "      raise UnsupportedMidiFileException\n",
        "    # Get pianoRoll binary Matrix for each of Soprano and alto parts\n",
        "    pr_s = get_pianoroll(midi.instruments[0], 36, 84, seqlen, tempo[0])\n",
        "    pr_a = get_pianoroll(midi.instruments[1], 36, 84, seqlen, tempo[0])\n",
        "    pr_b = get_pianoroll(midi.instruments[2], 36, 84, seqlen, tempo[0])\n",
        "    # return pr_s, pr_a, keymode\n",
        "    return pr_s, pr_a, pr_b, keymode\n",
        "\n",
        "  else:\n",
        "    # Get a pianoroll which gathered all the parts\n",
        "    pr = get_pianoroll(midi, 36, 84, seqlen, tempo[0])\n",
        "    return pr, keymode"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MIDI file\n",
        "input_midi_path = '/content/drive/MyDrive/chorales/combined_notes2.mid'\n",
        "output_midi_path = '/content/drive/MyDrive/chorales/generated_note.mid'"
      ],
      "metadata": {
        "id": "ag12nuq8SWZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess the MIDI data\n",
        "def load_midi(file_path):\n",
        "  midi_data = pretty_midi.PrettyMIDI(file_path)\n",
        "  return midi_data"
      ],
      "metadata": {
        "id": "Urt6CMQLT1Th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ATTENTION! You may want to modify this function if you want to generate only one single note\n",
        "def create_sequence_from_midi(idi_data):\n",
        "  notes = []\n",
        "  for instrument in midi_data.instruments:\n",
        "    for note in instrument.notes:\n",
        "      notes.append((note.pitch, note.start))\n",
        "\n",
        "  # Sort the notes by start time\n",
        "  notes.sort(key=lambda x: x[1])\n",
        "\n",
        "  # Create a list of time intervals between notes\n",
        "  intervals = [notes[i+1][1] - notes[i][1] for i in range(len(notes)-1)]\n",
        "\n",
        "  return intervals"
      ],
      "metadata": {
        "id": "c9QI1y-fUopf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MIDI data and create a sequence of note intervals\n",
        "midi_data = load_midi(input_midi_path)\n",
        "note_intervals = create_sequence_from_midi(midi_data)"
      ],
      "metadata": {
        "id": "qAqW8TB8X9H4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PFf8Dd3Ob_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44b2ea92-f1dd-45c4-b280-c1974302da2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "skip\n",
            "skip\n",
            "skip\n"
          ]
        }
      ],
      "source": [
        "# code 4.3, prepare MIDI data for the model\n",
        "# set the path for the MIDI file\n",
        "dir = \"drive/MyDrive/chorales/midi/\"\n",
        "\n",
        "x_all = [] # the list which stores inputs of soprano melodies\n",
        "y_all = [] # the list which stores outputs of alto melodies\n",
        "keymodes = [] # the list which stores the key whether it is major or minor\n",
        "files = [] # stores the filenames of the MIDI files\n",
        "\n",
        "# repeat the process with all the midi files\n",
        "for f in glob.glob(dir + \"/*.mid\"):\n",
        "  # print(f)\n",
        "  try:\n",
        "    # pr_s is for soprano pianoroll, pr_a is for alto, keymode is for either major 0 or minor 1\n",
        "    # pr_s, pr_a, keymode = read_midi(f, True, 64)\n",
        "    pr_s, pr_a, pr_b, keymode = read_midi(f, True, 64)\n",
        "    # add rests to the pianoroll\n",
        "    x = add_rest_nodes(pr_s)\n",
        "    y = add_rest_nodes(pr_a)\n",
        "    # x = add_rest_nodes(pr_b)\n",
        "    # y = add_rest_nodes(pr_a)\n",
        "\n",
        "    # add pianorolls which have been added rest elements to the lists\n",
        "    x_all.append(x)\n",
        "    y_all.append(y)\n",
        "    keymodes.append(keymode)\n",
        "    files.append(f)\n",
        "  # throw exception for midi data which can not be used\n",
        "  except UnsupportedMidiFileException:\n",
        "    print(\"skip\")\n",
        "# convert x_all and y_all into NumPy array to make them more useful later\n",
        "x_all = np.array(x_all)\n",
        "y_all = np.array(y_all)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# apply half of the data you stored for training data, and the other half for test data\n",
        "# the ratio should be 1:1\n",
        "i_train, i_test = train_test_split(range(len(x_all)),\n",
        "                                   test_size=int(len(x_all)/2),\n",
        "                                   shuffle=False)\n",
        "x_train = x_all[i_train]\n",
        "x_test = x_all[i_test]\n",
        "y_train = y_all[i_train]\n",
        "y_test = y_all[i_test]"
      ],
      "metadata": {
        "id": "CT2SimU4cbEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make and train the model here (LSTM), referred the code 5.1 from the prof book\n",
        "# code 5.1- implementation of encoder\n",
        "\n",
        "seq_length = x_train.shape[1] # time length\n",
        "input_dim = x_train.shape[2] # the number of input dimension\n",
        "encoded_dim = 16 # the number of vectors you want to compress into\n",
        "lstm_dim = 1024 # The book's suggested value is 1024. the number of RNN(LSTM) layers' hidden node.\n",
        "\n",
        "# make an empty model as an encoder part\n",
        "encoder = tf.keras.Sequential()\n",
        "# add RNN(LSTM) layers to the model\n",
        "# return_sequence=Flase means it only returns t he last time vector's value\n",
        "encoder.add(tf.keras.layers.LSTM(\n",
        "    lstm_dim, input_shape=(seq_length, input_dim),\n",
        "    use_bias=True, activation=\"tanh\", return_sequences=False\n",
        "    ))\n",
        "#add output layers (encoded_dim will be the number o nodes)\n",
        "encoder.add(tf.keras.layers.Dense(\n",
        "    encoded_dim, use_bias=True, activation=\"linear\"\n",
        "))\n",
        "# display the model\n",
        "encoder.summary()"
      ],
      "metadata": {
        "id": "iw3HK5M2YVhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code 5.2- Implement decoder\n",
        "\n",
        "#make an empty model\n",
        "decoder = tf.keras.Sequential()\n",
        "# Time-series by repeating input layer vectors to be able to add the later RNN(LSTM)\n",
        "decoder.add(tf.keras.layers.RepeatVector(\n",
        "    seq_length, input_dim=encoded_dim\n",
        "  ))\n",
        "# make LSTM layers and add them to the model\n",
        "decoder.add(tf.keras.layers.LSTM(\n",
        "    lstm_dim, use_bias=True, activation=\"tanh\",\n",
        "    return_sequences=True\n",
        "    ))\n",
        "\n",
        "# add output layers to the model. The number of nodes should equal the input's\n",
        "# return_sequncces is True because decoder is a time-series\n",
        "# use softmax because the output is one-hot vectors on every time stamps\n",
        "decoder.add(tf.keras.layers.Dense(\n",
        "    input_dim, use_bias=True, activation=\"softmax\"\n",
        "    ))\n",
        "#display it\n",
        "decoder.summary()"
      ],
      "metadata": {
        "id": "_opCxCEhanKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code 5.3- concatnate encoder and decoder to make an Auto-encoder\n",
        "# check\n",
        "\n",
        "# make a model\n",
        "model = tf.keras.Model(encoder.inputs, decoder(encoder.outputs))\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\",\n",
        "              metrics=\"categorical_accuracy\")\n",
        "# dispay\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Zj3gW9Arcr43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code 5.4 - the 1st and the 2nd arguments should be the same as input and output should be the same\n",
        "model.fit(x_train, x_train, batch_size=32, epochs=500)"
      ],
      "metadata": {
        "id": "x6MDl0AUdXry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code 5.5\n",
        "model.evaluate(x_test, x_test)"
      ],
      "metadata": {
        "id": "w7vi_19odiIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the next note (Using the trained model)\n",
        "def generate_next_note(model, input_sequence):\n",
        "  # Use the model to predict the next note\n",
        "  next_note = model.predict(input_sequence)\n",
        "\n",
        "  return next_note"
      ],
      "metadata": {
        "id": "aV5xOlGYjOq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the next note\n",
        "next_note = generate_next_note(model, x_test)"
      ],
      "metadata": {
        "id": "tJhYjvJCj11a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bf6fae9-80d1-4320-ccd9-fd1384e88e64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 32ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(next_note)"
      ],
      "metadata": {
        "id": "fwt4soc9ssis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_midi_from_notes(notes, output_path):\n",
        "    # Create a PrettyMIDI object\n",
        "    midi_data = pretty_midi.PrettyMIDI()\n",
        "\n",
        "    # Create an Instrument instance for the generated notes\n",
        "    instrument = pretty_midi.Instrument(0)\n",
        "\n",
        "    time = 0  # Initialize the time\n",
        "\n",
        "    # Define a function to convert values in the range [0, 1] to MIDI velocities (0-127)\n",
        "    def velocity_to_midi(value):\n",
        "        return int(value * 127)\n",
        "\n",
        "    # Iterate through the generated notes and create Note instances\n",
        "    for step in range(len(notes)):\n",
        "        for note_num, velocity in enumerate(notes[step][0]):\n",
        "            if velocity > 0:  # Check if the velocity is greater than 0\n",
        "                # Convert the value to MIDI velocity\n",
        "                midi_velocity = velocity_to_midi(velocity)\n",
        "\n",
        "                # Create a Note instance for each active note\n",
        "                note = pretty_midi.Note(velocity=midi_velocity, pitch=note_num, start=time, end=time+1/32)  # Adjust the duration as needed\n",
        "                instrument.notes.append(note)\n",
        "\n",
        "        # Increment the time by one time step\n",
        "        time += 1/32  # Adjust the time step as needed\n",
        "\n",
        "    # Add the instrument to the MIDI object\n",
        "    midi_data.instruments.append(instrument)\n",
        "\n",
        "    # Write the MIDI data to a file\n",
        "    midi_data.write(output_path)\n"
      ],
      "metadata": {
        "id": "xQXT7yx0dXCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_midi_from_notes(next_note, output_midi_path)"
      ],
      "metadata": {
        "id": "i4sZjXoAc0Ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# failed attempt 1\n",
        "\n",
        "# # Extract the pitch of the first note from next_note\n",
        "# next_note_scalar = int(next_note[0][0][0])\n",
        "\n",
        "# # Create a PrettyMIDI object for the next note\n",
        "# output_midi = pretty_midi.PrettyMIDI()\n",
        "# instrument = pretty_midi.Instrument(0)\n",
        "\n",
        "# # Add the next note to the instrument\n",
        "# instrument.notes.append(pretty_midi.Note(\n",
        "#     velocity=64, pitch=next_note_scalar, start=0, end=1\n",
        "# ))\n",
        "\n",
        "# # Add the instrument to the MIDI file\n",
        "# output_midi.instruments.append(instrument)\n",
        "\n",
        "# # Save the generated note as a new MIDI file\n",
        "# output_midi.write(output_midi_path)\n"
      ],
      "metadata": {
        "id": "YHfE13TOVUTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# failed attempt 2\n",
        "\n",
        "# def generate_midi_from_notes(notes, output_path):\n",
        "#     # Create a PrettyMIDI object\n",
        "#     midi_data = pretty_midi.PrettyMIDI()\n",
        "\n",
        "#     # Create an Instrument instance for the generated notes\n",
        "#     instrument = pretty_midi.Instrument(0)\n",
        "\n",
        "#     time = 0  # Initialize the time\n",
        "\n",
        "#     # Iterate through the generated notes and create Note instances\n",
        "#     for step in range(len(notes)):\n",
        "#         for note_num, velocity in enumerate(notes[step]):\n",
        "#             if velocity.any() > 0: # to check if any value is greater than 0\n",
        "\n",
        "#                 # round the velocity to the nearest integer\n",
        "#                 velocity = np.round(velocity).astype(int)\n",
        "\n",
        "#                 # ensure the velocity is within the valid MIDI range(0-127)\n",
        "#                 velocity = np.maximum(0, np.minimum(velocity, 127))\n",
        "\n",
        "#                 # Create a Note instance for each active note\n",
        "#                 note = pretty_midi.Note(velocity=velocity, pitch=note_num, start=time, end=time+1/32)  # Adjust the duration as needed\n",
        "#                 instrument.notes.append(note)\n",
        "\n",
        "#         # Increment the time by one time step\n",
        "#         time += 1/32  # Adjust the time step as needed\n",
        "\n",
        "#     # Add the instrument to the MIDI object\n",
        "#     midi_data.instruments.append(instrument)\n",
        "\n",
        "#     # Write the MIDI data to a file\n",
        "#     print(output_path)\n",
        "#     midi_data.write(output_path)\n",
        "\n",
        "# # Generate the MIDI data from \"next_note\" and save it to a file\n",
        "# generate_midi_from_notes(next_note, output_midi_path)"
      ],
      "metadata": {
        "id": "0WNXDTXsX9br"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# failed attempt 3\n",
        "\n",
        "# def generate_midi_from_notes(notes, output_path):\n",
        "#     # Create a PrettyMIDI object\n",
        "#     midi_data = pretty_midi.PrettyMIDI()\n",
        "\n",
        "#     # Create an Instrument instance for the generated notes\n",
        "#     instrument = pretty_midi.Instrument(0)\n",
        "\n",
        "#     time = 0  # Initialize the time\n",
        "\n",
        "#     # Iterate through the generated notes and create Note instances\n",
        "#     for step in range(len(notes)):\n",
        "#         for note_num, velocity in enumerate(notes[step]):\n",
        "#             if np.any(velocity > 0):  # Use np.any() to check if any value is greater than zero\n",
        "#                 # Round the velocity to the nearest integer using np.round\n",
        "#                 velocity = np.round(velocity).astype(int)\n",
        "\n",
        "#                 # Ensure the velocity is within the valid MIDI range (0-127)\n",
        "#                 velocity = np.maximum(0, np.minimum(velocity, 127))\n",
        "\n",
        "#                 # Create a Note instance for each active note\n",
        "#                 note = pretty_midi.Note(velocity=velocity, pitch=note_num, start=time, end=time+1/32)  # Adjust the duration as needed\n",
        "#                 instrument.notes.append(note)\n",
        "\n",
        "#         # Increment the time by one time step\n",
        "#         time += 1/32  # Adjust the time step as needed\n",
        "\n",
        "#     # Add the instrument to the MIDI object\n",
        "#     midi_data.instruments.append(instrument)\n",
        "\n",
        "#     # Write the MIDI data to a file\n",
        "#     midi_data.write(output_path)\n"
      ],
      "metadata": {
        "id": "jyf6l6GbcpfT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}