{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TombCrawler/nihonAI/blob/main/Nov1stMiniGen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nov１st 教授emailより：簡単で構いませんので、メロディデータに対して、\n",
        "数個の音符列を入力すると、その次の音符を予測する\n",
        "というモデルをTensorFlowで作る"
      ],
      "metadata": {
        "id": "PBmlXfcjR2Un"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yb4Xw_GNRrSc"
      },
      "outputs": [],
      "source": [
        "!pip install midi2audio\n",
        "!apt install fluidsynth\n",
        "!pip install pretty_midi\n",
        "!pip install mido\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list | grep jax"
      ],
      "metadata": {
        "id": "Cmxd-0B5UIK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U jax jaxlib"
      ],
      "metadata": {
        "id": "RnwgXByXUP4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import os\n",
        "import glob\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from mpl_toolkits.mplot3d.axes3d import Axes3D\n",
        "\n",
        "import pretty_midi\n",
        "import IPython.display as ipd\n",
        "from midi2audio import FluidSynth\n",
        "from music21 import *\n",
        "\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "import mido\n",
        "from mido import MidiFile, MidiTrack, Message"
      ],
      "metadata": {
        "id": "Jh6F2ETiSSEp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "3J3WJGTISmyy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da60d1eb-629f-4b74-eb50-f71f6cf1dbf6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MIDI file\n",
        "input_midi_path = '/content/drive/MyDrive/chorales/combined_notes2.mid'\n",
        "output_midi_path = '/content/drive/MyDrive/chorales/generated_note.mid'"
      ],
      "metadata": {
        "id": "ag12nuq8SWZe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UnsupportedMidiFileException(Exception):\n",
        "  \"Unsupported MIDI File\""
      ],
      "metadata": {
        "id": "8Jf4KnG-nUfK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nn_from: the lowest pitch(including this number)\n",
        "# nn_thru: the heighest pitch (Excluding this number)\n",
        "# seqlen: the element towards time axis, turn out to be the number of measure. If you give 64 to seqlen based on eighth note, it has 8 measures\n",
        "#       The song's length(pianoroll.shape[1] must be longer than 64)\n",
        "# tempo: tempo\n",
        "def get_pianoroll(midi, nn_from, nn_thru, seqlen, tempo):\n",
        "  pianoroll = midi.get_piano_roll(fs=2*tempo/60)\n",
        "  print(f\"seqlen!!{seqlen}\")\n",
        "  print(f\"piano_roll.shape[1] a.k.a song length!{pianoroll.shape[1]}\")\n",
        "  if pianoroll.shape[1] < seqlen:\n",
        "    raise UnsupportedMidiFileException\n",
        "  pianoroll = pianoroll[nn_from:nn_thru, 0:seqlen]\n",
        "  pianoroll = np.heaviside(pianoroll, 0)\n",
        "  return np.transpose(pianoroll)"
      ],
      "metadata": {
        "id": "j1Erq4mroDdr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add rest nodes to the binary piano roll matrix to make the one-hot representation function\n",
        "\n",
        "# add rest nodes\n",
        "def add_rest_nodes(pianoroll):\n",
        "  # make a \"rest node series\"\n",
        "  # If all the elemets are zero, the rest node says 1, else 0\n",
        "  print(f\"pinoroll!\\n{pianoroll}\")\n",
        "  rests = 1 - np.sum(pianoroll, axis=1)\n",
        "  print(f\"rests!\\n{rests}\")\n",
        "\n",
        "  # Make the \"rest node series\" a 2D array. To use it as a matrix, it's reshaped into a 2D array with a single column.\n",
        "  rests = np.expand_dims(rests, 1)\n",
        "  print(f\"2D rests!\\n{rests}\")\n",
        "  print(f\"concatenated!\\n{np.concatenate([pianoroll, rests], axis=1)}\")\n",
        "  # Concatenate the binary pianoroll matrix and the rest node series matrix and return it\n",
        "  return np.concatenate([pianoroll, rests], axis=1)"
      ],
      "metadata": {
        "id": "YHeYzMV0oV4F"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ciZCwV9mrEHK"
      },
      "outputs": [],
      "source": [
        "def read_midi(filename, sop_alto, seqlen):\n",
        "  # read midi file\n",
        "  midi = pretty_midi.PrettyMIDI(filename)\n",
        "\n",
        "  # An Exception error is thrown if there is a modulation(key change)\n",
        "  if len(midi.key_signature_changes) !=1:\n",
        "    raise UnsupportedMidiFileException\n",
        "\n",
        "  # Modulate the given key to C major or C minor\n",
        "  key_number = midi.key_signature_changes[0].key_number\n",
        "  # transpose_to_c(midi, key_number)\n",
        "\n",
        "  # Get Major key(keynode=0) or Minor key(keynode=1)\n",
        "  # key_number has values ​​from 0 to 11 for major keys and for minor keys,\n",
        "  # 12~23 is included, so by dividing it by 12 and converting it to an integer,\n",
        "  # it will be 0 if it is a major key,\n",
        "  # If it is a minor key, we find the value 1 and assign it to keymode.\n",
        "  keymode = np.array([int(key_number / 12)])\n",
        "\n",
        "  # The Exception error thrown when tempo changes\n",
        "  tempo_time, tempo = midi.get_tempo_changes()\n",
        "  print(f\"tempo_changes{midi.get_tempo_changes()}\")\n",
        "  print(f\"tempo_time{tempo_time}, tempo{tempo}\")\n",
        "  if len(tempo) != 1: # counting the number of elements in the tempo array\n",
        "    raise UnsupportedMidiFileException\n",
        "\n",
        "  if sop_alto: # The argument is coming in as boolean, True or False\n",
        "    # The exception thrown if there are less than 2 parts\n",
        "    if len(midi.instruments) < 2:\n",
        "      raise UnsupportedMidiFileException\n",
        "\n",
        "    # Get pianoRoll binary Matrix for each of Soprano and alto parts\n",
        "    pr_s = get_pianoroll(midi.instruments[0], 36, 84, seqlen, tempo[0])\n",
        "    pr_a = get_pianoroll(midi.instruments[1], 36, 84, seqlen, tempo[0])\n",
        "    pr_b = get_pianoroll(midi.instruments[2], 36, 84, seqlen, tempo[0])\n",
        "\n",
        "    # return pr_s, pr_a, keymode\n",
        "    return pr_s, pr_a, pr_b, keymode\n",
        "\n",
        "  else:\n",
        "    # Get a pianoroll which gathered all the parts\n",
        "    pr = get_pianoroll(midi, 36, 84, seqlen, tempo[0])\n",
        "    return pr, keymode"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# oA_ Load and preprocess the MIDI data\n",
        "def load_midi(file_path):\n",
        "  midi_data = pretty_midi.PrettyMIDI(file_path)\n",
        "  return midi_data"
      ],
      "metadata": {
        "id": "Urt6CMQLT1Th"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# oA_ ATTENTION! You may want to modify this function if you want to generate only one single note\n",
        "def create_sequence_from_midi(idi_data):\n",
        "  notes = []\n",
        "  for instrument in midi_data.instruments:\n",
        "    for note in instrument.notes:\n",
        "      notes.append((note.pitch, note.start))\n",
        "\n",
        "  # Sort the notes by start time\n",
        "  notes.sort(key=lambda x: x[1])\n",
        "\n",
        "  # Create a list of time intervals between notes\n",
        "  intervals = [notes[i+1][1] - notes[i][1] for i in range(len(notes)-1)]\n",
        "\n",
        "  return intervals"
      ],
      "metadata": {
        "id": "c9QI1y-fUopf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# oA_ Load the MIDI data and create a sequence of note intervals\n",
        "midi_data = load_midi(input_midi_path)\n",
        "note_intervals = create_sequence_from_midi(midi_data)"
      ],
      "metadata": {
        "id": "qAqW8TB8X9H4"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PFf8Dd3Ob_7"
      },
      "outputs": [],
      "source": [
        "# code 4.3, prepare MIDI data for the model\n",
        "# set the path for the MIDI file\n",
        "dir = \"drive/MyDrive/chorales/midi/\"\n",
        "\n",
        "x_all = [] # the list which stores inputs of soprano melodies\n",
        "y_all = [] # the list which stores outputs of alto melodies\n",
        "keymodes = [] # the list which stores the key whether it is major or minor\n",
        "files = [] # stores the filenames of the MIDI files\n",
        "\n",
        "# repeat the process with all the midi files\n",
        "for f in glob.glob(dir + \"/*.mid\"):\n",
        "  print(f)\n",
        "  try:\n",
        "    # pr_s is for soprano pianoroll, pr_a is for alto, keymode is for either major 0 or minor 1\n",
        "    # pr_s, pr_a, keymode = read_midi(f, True, 64)\n",
        "    pr_s, pr_a, pr_b, keymode = read_midi(f, True, 64)\n",
        "    # add rests to the pianoroll\n",
        "    x = add_rest_nodes(pr_s)\n",
        "    y = add_rest_nodes(pr_a)\n",
        "    # x = add_rest_nodes(pr_b)\n",
        "    # y = add_rest_nodes(pr_a)\n",
        "\n",
        "    # add pianorolls which have been added rest elements to the lists\n",
        "    x_all.append(x)\n",
        "    y_all.append(y)\n",
        "    keymodes.append(keymode)\n",
        "    files.append(f)\n",
        "  # throw exception for midi data which can not be  used\n",
        "  except UnsupportedMidiFileException:\n",
        "    print(\"skip\")\n",
        "# convert x_all and y_all into NumPy array to make them more useful later\n",
        "x_all = np.array(x_all)\n",
        "y_all = np.array(y_all)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# apply half of the data you stored for training data, and the other half for test data\n",
        "# the ratio should be 1:1\n",
        "i_train, i_test = train_test_split(range(len(x_all)),\n",
        "                                   test_size=int(len(x_all)/2),\n",
        "                                   shuffle=False)\n",
        "x_train = x_all[i_train]\n",
        "x_test = x_all[i_test]\n",
        "y_train = y_all[i_train]\n",
        "y_test = y_all[i_test]"
      ],
      "metadata": {
        "id": "CT2SimU4cbEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make and train the model here (LSTM), referred the code 5.1 from the prof book\n",
        "# code 5.1- implementation of encoder\n",
        "\n",
        "seq_length = x_train.shape[1] # time length\n",
        "input_dim = x_train.shape[2] # the number of input dimension\n",
        "encoded_dim = 16 # the number of vectors you want to compress into\n",
        "lstm_dim = 1024 # The book's suggested value is 1024. the number of RNN(LSTM) layers' hidden node.\n",
        "\n",
        "# make an empty model as an encoder part\n",
        "encoder = tf.keras.Sequential()\n",
        "# add RNN(LSTM) layers to the model\n",
        "# return_sequence=Flase means it only returns t he last time vector's value\n",
        "encoder.add(tf.keras.layers.LSTM(\n",
        "    lstm_dim, input_shape=(seq_length, input_dim),\n",
        "    use_bias=True, activation=\"tanh\", return_sequences=False\n",
        "    ))\n",
        "#add output layers (encoded_dim will be the number o nodes)\n",
        "encoder.add(tf.keras.layers.Dense(\n",
        "    encoded_dim, use_bias=True, activation=\"linear\"\n",
        "))\n",
        "# display the model\n",
        "encoder.summary()"
      ],
      "metadata": {
        "id": "iw3HK5M2YVhG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b06a01c-c069-461c-dd1f-3a654fce7115"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 1024)              4399104   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                16400     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4415504 (16.84 MB)\n",
            "Trainable params: 4415504 (16.84 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# code 5.2- Implement decoder\n",
        "\n",
        "#make an empty model\n",
        "decoder = tf.keras.Sequential()\n",
        "# Time-series by repeating input layer vectors to be able to add the later RNN(LSTM)\n",
        "decoder.add(tf.keras.layers.RepeatVector(\n",
        "    seq_length, input_dim=encoded_dim\n",
        "  ))\n",
        "# make LSTM layers and add them to the model\n",
        "decoder.add(tf.keras.layers.LSTM(\n",
        "    lstm_dim, use_bias=True, activation=\"tanh\",\n",
        "    return_sequences=True\n",
        "    ))\n",
        "\n",
        "# add output layers to the model. The number of nodes should equal the input's\n",
        "# return_sequncces is True because decoder is a time-series\n",
        "# use softmax because the output is one-hot vectors on every time stamps\n",
        "decoder.add(tf.keras.layers.Dense(\n",
        "    input_dim, use_bias=True, activation=\"softmax\"\n",
        "    ))\n",
        "#display it\n",
        "decoder.summary()"
      ],
      "metadata": {
        "id": "_opCxCEhanKb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1c11bcd-636c-4aff-88a6-b952193f342d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " repeat_vector (RepeatVecto  (None, 64, 16)            0         \n",
            " r)                                                              \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64, 1024)          4263936   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64, 49)            50225     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4314161 (16.46 MB)\n",
            "Trainable params: 4314161 (16.46 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# code 5.3- concatnate encoder and decoder to make an Auto-encoder\n",
        "# check\n",
        "\n",
        "# make a model\n",
        "model = tf.keras.Model(encoder.inputs, decoder(encoder.outputs))\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\",\n",
        "              metrics=\"categorical_accuracy\")\n",
        "# dispay\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Zj3gW9Arcr43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9502c2e-74b5-4608-8878-550ce6bbf128"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_input (InputLayer)     [(None, 64, 49)]          0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 1024)              4399104   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                16400     \n",
            "                                                                 \n",
            " sequential_1 (Sequential)   (None, 64, 49)            4314161   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8729665 (33.30 MB)\n",
            "Trainable params: 8729665 (33.30 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# code 5.4 - the 1st and the 2nd arguments should be the same as input and output should be the same\n",
        "model.fit(x_train, x_train, batch_size=32, epochs=500)"
      ],
      "metadata": {
        "id": "x6MDl0AUdXry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code 5.5\n",
        "model.evaluate(x_test, x_test)"
      ],
      "metadata": {
        "id": "w7vi_19odiIA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "773740b1-06e5-4a79-db88-5e6f07d0ecd1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 1s 23ms/step - loss: 5.0748 - categorical_accuracy: 0.3363\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5.074792861938477, 0.33628541231155396]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the next note (Using the trained model)\n",
        "def generate_next_note(model, input_sequence):\n",
        "  # Use the model to predict the next note\n",
        "  next_note = model.predict(input_sequence)\n",
        "\n",
        "  return next_note"
      ],
      "metadata": {
        "id": "aV5xOlGYjOq9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the next note\n",
        "next_note = generate_next_note(model, x_test)"
      ],
      "metadata": {
        "id": "tJhYjvJCj11a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70adcdd5-31f9-4d8e-9654-5b3b00fa5eb7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 1s 28ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(next_note)"
      ],
      "metadata": {
        "id": "fwt4soc9ssis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_midi_from_notes(notes, output_path):\n",
        "    # Create a PrettyMIDI object\n",
        "    midi_data = pretty_midi.PrettyMIDI()\n",
        "\n",
        "    # Create an Instrument instance for the generated notes\n",
        "    instrument = pretty_midi.Instrument(0)\n",
        "\n",
        "    time = 0  # Initialize the time\n",
        "\n",
        "    # Define a function to convert values in the range [0, 1] to MIDI velocities (0-127)\n",
        "    def velocity_to_midi(value):\n",
        "        return int(value * 127)\n",
        "\n",
        "    # Iterate through the generated notes and create Note instances\n",
        "    for step in range(len(notes)):\n",
        "        for note_num, velocity in enumerate(notes[step][0]):\n",
        "            if velocity > 0:  # Check if the velocity is greater than 0\n",
        "                # Convert the value to MIDI velocity\n",
        "                midi_velocity = velocity_to_midi(velocity)\n",
        "\n",
        "                # Create a Note instance for each active note\n",
        "                note = pretty_midi.Note(velocity=midi_velocity, pitch=note_num, start=time, end=time+1/32)  # Adjust the duration as needed\n",
        "                instrument.notes.append(note)\n",
        "\n",
        "        # Increment the time by one time step\n",
        "        time += 1/32  # Adjust the time step as needed\n",
        "\n",
        "    # Add the instrument to the MIDI object\n",
        "    midi_data.instruments.append(instrument)\n",
        "\n",
        "    # Write the MIDI data to a file\n",
        "    midi_data.write(output_path)\n"
      ],
      "metadata": {
        "id": "xQXT7yx0dXCv"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_midi_from_notes(next_note, output_midi_path)"
      ],
      "metadata": {
        "id": "i4sZjXoAc0Ui"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# failed attempt 1\n",
        "\n",
        "# # Extract the pitch of the first note from next_note\n",
        "# next_note_scalar = int(next_note[0][0][0])\n",
        "\n",
        "# # Create a PrettyMIDI object for the next note\n",
        "# output_midi = pretty_midi.PrettyMIDI()\n",
        "# instrument = pretty_midi.Instrument(0)\n",
        "\n",
        "# # Add the next note to the instrument\n",
        "# instrument.notes.append(pretty_midi.Note(\n",
        "#     velocity=64, pitch=next_note_scalar, start=0, end=1\n",
        "# ))\n",
        "\n",
        "# # Add the instrument to the MIDI file\n",
        "# output_midi.instruments.append(instrument)\n",
        "\n",
        "# # Save the generated note as a new MIDI file\n",
        "# output_midi.write(output_midi_path)\n"
      ],
      "metadata": {
        "id": "YHfE13TOVUTV"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# failed attempt 2\n",
        "\n",
        "# def generate_midi_from_notes(notes, output_path):\n",
        "#     # Create a PrettyMIDI object\n",
        "#     midi_data = pretty_midi.PrettyMIDI()\n",
        "\n",
        "#     # Create an Instrument instance for the generated notes\n",
        "#     instrument = pretty_midi.Instrument(0)\n",
        "\n",
        "#     time = 0  # Initialize the time\n",
        "\n",
        "#     # Iterate through the generated notes and create Note instances\n",
        "#     for step in range(len(notes)):\n",
        "#         for note_num, velocity in enumerate(notes[step]):\n",
        "#             if velocity.any() > 0: # to check if any value is greater than 0\n",
        "\n",
        "#                 # round the velocity to the nearest integer\n",
        "#                 velocity = np.round(velocity).astype(int)\n",
        "\n",
        "#                 # ensure the velocity is within the valid MIDI range(0-127)\n",
        "#                 velocity = np.maximum(0, np.minimum(velocity, 127))\n",
        "\n",
        "#                 # Create a Note instance for each active note\n",
        "#                 note = pretty_midi.Note(velocity=velocity, pitch=note_num, start=time, end=time+1/32)  # Adjust the duration as needed\n",
        "#                 instrument.notes.append(note)\n",
        "\n",
        "#         # Increment the time by one time step\n",
        "#         time += 1/32  # Adjust the time step as needed\n",
        "\n",
        "#     # Add the instrument to the MIDI object\n",
        "#     midi_data.instruments.append(instrument)\n",
        "\n",
        "#     # Write the MIDI data to a file\n",
        "#     print(output_path)\n",
        "#     midi_data.write(output_path)\n",
        "\n",
        "# # Generate the MIDI data from \"next_note\" and save it to a file\n",
        "# generate_midi_from_notes(next_note, output_midi_path)"
      ],
      "metadata": {
        "id": "0WNXDTXsX9br"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# failed attempt 3\n",
        "\n",
        "# def generate_midi_from_notes(notes, output_path):\n",
        "#     # Create a PrettyMIDI object\n",
        "#     midi_data = pretty_midi.PrettyMIDI()\n",
        "\n",
        "#     # Create an Instrument instance for the generated notes\n",
        "#     instrument = pretty_midi.Instrument(0)\n",
        "\n",
        "#     time = 0  # Initialize the time\n",
        "\n",
        "#     # Iterate through the generated notes and create Note instances\n",
        "#     for step in range(len(notes)):\n",
        "#         for note_num, velocity in enumerate(notes[step]):\n",
        "#             if np.any(velocity > 0):  # Use np.any() to check if any value is greater than zero\n",
        "#                 # Round the velocity to the nearest integer using np.round\n",
        "#                 velocity = np.round(velocity).astype(int)\n",
        "\n",
        "#                 # Ensure the velocity is within the valid MIDI range (0-127)\n",
        "#                 velocity = np.maximum(0, np.minimum(velocity, 127))\n",
        "\n",
        "#                 # Create a Note instance for each active note\n",
        "#                 note = pretty_midi.Note(velocity=velocity, pitch=note_num, start=time, end=time+1/32)  # Adjust the duration as needed\n",
        "#                 instrument.notes.append(note)\n",
        "\n",
        "#         # Increment the time by one time step\n",
        "#         time += 1/32  # Adjust the time step as needed\n",
        "\n",
        "#     # Add the instrument to the MIDI object\n",
        "#     midi_data.instruments.append(instrument)\n",
        "\n",
        "#     # Write the MIDI data to a file\n",
        "#     midi_data.write(output_path)\n"
      ],
      "metadata": {
        "id": "jyf6l6GbcpfT"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}