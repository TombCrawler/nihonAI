{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TombCrawler/nihonAI/blob/main/Nov1stMiniGen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nov１st 教授emailより：簡単で構いませんので、メロディデータに対して、\n",
        "数個の音符列を入力すると、その次の音符を予測する\n",
        "というモデルをTensorFlowで作る"
      ],
      "metadata": {
        "id": "PBmlXfcjR2Un"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yb4Xw_GNRrSc"
      },
      "outputs": [],
      "source": [
        "!pip install midi2audio\n",
        "!apt install fluidsynth\n",
        "!pip install pretty_midi\n",
        "!pip install mido\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list | grep jax"
      ],
      "metadata": {
        "id": "Cmxd-0B5UIK0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1f7c538-c504-49c6-fd01-ebf51d3fccf1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jax                              0.4.20\n",
            "jaxlib                           0.4.20+cuda11.cudnn86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U jax jaxlib"
      ],
      "metadata": {
        "id": "RnwgXByXUP4k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88fa8a28-8b89-4b50-f179-3fe9b62ba401"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (0.4.20)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (0.4.20+cuda11.cudnn86)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from jax) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax) (1.11.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import os\n",
        "import glob\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from mpl_toolkits.mplot3d.axes3d import Axes3D\n",
        "\n",
        "import pretty_midi\n",
        "import IPython.display as ipd\n",
        "from midi2audio import FluidSynth\n",
        "from music21 import *\n",
        "\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow_probability as tfp\n",
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "import mido\n",
        "from mido import MidiFile, MidiTrack, Message\n",
        "\n",
        "np.set_printoptions(threshold=np.inf)"
      ],
      "metadata": {
        "id": "Jh6F2ETiSSEp"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "3J3WJGTISmyy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "919c9b2d-e8cc-415c-e800-4f65cb458aa6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here trying to convert MIDI file to a numpy array, partially [referred](https://medium.com/analytics-vidhya/convert-midi-file-to-numpy-array-in-python-7d00531890c) but eventually failed\n"
      ],
      "metadata": {
        "id": "ejGgENnnksO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UnsupportedMidiFileException(Exception):\n",
        "  \"Unsupported MIDI File\""
      ],
      "metadata": {
        "id": "8Jf4KnG-nUfK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get_PianoRoll explanation<br>\n",
        "nn_from: the lowest pitch(including this number)<br>\n",
        "nn_thru: the heighest pitch (Excluding this number) <br>\n",
        "seqlen: the element towards time axis, turn out to be the number of measure. If you give 64 to seqlen based on eighth note, it has 8 measures<br>\n",
        "The song's length(pianoroll.shape[1] must be longer than 64) <br>\n",
        "tempo: tempo<br>\n",
        "<br>\n",
        "About Transpose: <br>\n",
        "Transposing a NumPy array changes its shape. If the original array has a shape of (48, n), where n is the number of columns, transposing it will result in an array with a shape of (n, 48). So, if the original array had 48 rows and n columns, after transposing, it would have n rows and 48 columns.\n",
        "\n",
        "The change in the number of elements or length from 48 to 64 after transposing means that the number of columns in the original binary_pianoroll was 64. Therefore, the transposed array has 64 rows and 48 columns.<br>\n",
        "This is a 64*48 Matrix, 3072 parameters\n"
      ],
      "metadata": {
        "id": "rPAmFXu8zF0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pianoroll(midi, nn_from, nn_thru, seqlen, tempo):\n",
        "  pianoroll = midi.get_piano_roll(fs=2*tempo/60)\n",
        "\n",
        "  # print(f\"seqlen!!{seqlen}\")\n",
        "  # print(f\"piano_roll.shape[1] a.k.a song length!{pianoroll.shape[1]}\")\n",
        "\n",
        "  if pianoroll.shape[1] < seqlen:\n",
        "    raise UnsupportedMidiFileException\n",
        "\n",
        "  pianoroll = pianoroll[nn_from:nn_thru, 0:seqlen] # Pinoroll's value still NOT binary since it has velocity\n",
        "\n",
        "  binary_pianoroll = np.heaviside(pianoroll, 0) # converting as a binary matrix\n",
        "\n",
        "  transposed_pianoroll = np.transpose(binary_pianoroll)\n",
        "  # print(f\"Transposed \\n {transposed_pianoroll}, {len(transposed_pianoroll)}\")\n",
        "\n",
        "  return transposed_pianoroll"
      ],
      "metadata": {
        "id": "j1Erq4mroDdr"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "rests = np.expand_dims(rests, 1)\n",
        "<br>#the 1 as the second argument specifies the axis along which the new dimension will be added. <br>\n",
        "Make the \"rest node series\" a 2D array. To use it as a matrix, it's reshaped into a 2D array with a single column."
      ],
      "metadata": {
        "id": "J9_WQniG28Xv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add rest nodes to the piano roll matrix to make the one-hot representation function\n",
        "\n",
        "def add_rest_nodes(pianoroll):\n",
        "  # make a \"rest node sequence\"\n",
        "  # If all the elemets are zero, the rest node says 1,(else 0)\n",
        "  # print(f\"pinoroll!\\n{pianoroll}\")\n",
        "\n",
        "  rests = 1 - np.sum(pianoroll, axis=1) # the elements in the pianoroll matrix are binary so either 1 or 0\n",
        "\n",
        "  print(f\"rests!\\n{rests}\")\n",
        "\n",
        "  rests = np.expand_dims(rests, 1)\n",
        "\n",
        "  # print(f\"2D rests!\\n{rests}\")\n",
        "  # print(f\"concatenated!\\n{np.concatenate([pianoroll, rests], axis=1)}\")\n",
        "\n",
        "  return np.concatenate([pianoroll, rests], axis=1) # Concatenate the binary pianoroll matrix and the rest node series matrix and return it"
      ],
      "metadata": {
        "id": "YHeYzMV0oV4F"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read_Midi Explanation <br>\n",
        "\n",
        "  Get Major key(keymode=0) or Minor key(keymode=1)<br>\n",
        "  key_number has values ​​from 0 to 11 for major keys and for minor keys,<br>\n",
        "  12~23 is included, so by dividing it by 12 and converting it to an integer,\n",
        "  it will be 0 if it is a major key,<br>\n",
        "  If it is a minor key, we find the value 1 and assign it to keymode.<br>"
      ],
      "metadata": {
        "id": "c_q9fawT3r92"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "ciZCwV9mrEHK"
      },
      "outputs": [],
      "source": [
        "def read_midi(filename, sop_alto, seqlen):\n",
        "  midi = pretty_midi.PrettyMIDI(filename)\n",
        "\n",
        "  if len(midi.key_signature_changes) !=1: # An Exception error is thrown if there is a modulation(key change)\n",
        "    raise UnsupportedMidiFileException\n",
        "\n",
        "  key_number = midi.key_signature_changes[0].key_number # explained in the text\n",
        "  # transpose_to_c(midi, key_number) # neccessary?\n",
        "\n",
        "  keymode = np.array([int(key_number / 12)])\n",
        "\n",
        "  # The Exception error thrown when tempo changes\n",
        "  tempo_time, tempo = midi.get_tempo_changes()\n",
        "\n",
        "  # print(f\"tempo_changes{midi.get_tempo_changes()}\")\n",
        "  # print(f\"tempo_time{tempo_time}, tempo{tempo}\")\n",
        "\n",
        "  if len(tempo) != 1: # counting the number of elements in the tempo array\n",
        "    raise UnsupportedMidiFileException\n",
        "\n",
        "  if sop_alto: # The argument is coming in as boolean, True or False\n",
        "    if len(midi.instruments) < 2: # The exception thrown if there are less than 2 parts\n",
        "      raise UnsupportedMidiFileException\n",
        "\n",
        "    # Get pianoRoll binary Matrix for each of Soprano and alto parts\n",
        "    pr_s = get_pianoroll(midi.instruments[0], 36, 84, seqlen, tempo[0])\n",
        "    pr_a = get_pianoroll(midi.instruments[1], 36, 84, seqlen, tempo[0])\n",
        "    pr_b = get_pianoroll(midi.instruments[2], 36, 84, seqlen, tempo[0])\n",
        "\n",
        "    # return pr_s, pr_a, keymode\n",
        "    return pr_s, pr_a, pr_b, keymode\n",
        "\n",
        "  else:\n",
        "    # Get a pianoroll which gathered all the parts\n",
        "    pr = get_pianoroll(midi, 36, 84, seqlen, tempo[0])\n",
        "    return pr, keymode"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read Midi data and store\n",
        "\n",
        "dir = \"drive/MyDrive/chorales/midi/\"\n",
        "for each_file in glob.glob(dir + \"/*.mid\"):\n",
        "  try:\n",
        "     soprano, alto, bass, keymode = read_midi(each_file, True, 64)\n",
        "\n",
        "     soprano_rest = add_rest_nodes(soprano)\n",
        "     alto_rest = add_rest_nodes(alto)\n",
        "     bass_rest = add_rest_nodes(bass)\n",
        "\n",
        "  except UnsupportedMidiFileException:\n",
        "     print(\"Nah\")"
      ],
      "metadata": {
        "id": "I00OptsC752g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----Unused or failed code below--------"
      ],
      "metadata": {
        "id": "SXQlLF2I84y4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# about heaviside step function\n",
        "# If the first argument value is 0, the program choose the second argument's value\n",
        "# If the first arg value is > 0, it prints 1\n",
        "# if the first arg value is < 0, it prints 0\n",
        "# import numpy as np\n",
        "\n",
        "# x = np.array([-1.5, 0.5, 0, 0.5, 1.5])\n",
        "# gfg = np.heaviside(x, 777)\n",
        "\n",
        "# print(gfg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0DO_4GvdDW6",
        "outputId": "5f570741-779d-4977-87d9-5cb2bff4ba7c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  0.   1. 777.   1.   1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unused # Make a model here (LSTM), referred the code 5.1 from the prof book\n",
        "# # code 5.1- implementation of encoder\n",
        "\n",
        "# seq_length = x_train.shape[1] # time length\n",
        "# input_dim = x_train.shape[2] # the number of input dimension\n",
        "# encoded_dim = 16 # the number of vectors you want to compress into\n",
        "# lstm_dim = 1024 # The book's suggested value is 1024. the number of RNN(LSTM) layers' hidden node.\n",
        "\n",
        "# # make an empty model as an encoder part\n",
        "# encoder = tf.keras.Sequential()\n",
        "\n",
        "# # add RNN(LSTM) layers to the model\n",
        "# # return_sequence=Flase means it only returns t he last time vector's value\n",
        "# encoder.add(tf.keras.layers.LSTM(\n",
        "#     lstm_dim, input_shape=(seq_length, input_dim),\n",
        "#     use_bias=True, activation=\"tanh\", return_sequences=False\n",
        "#     ))\n",
        "# #add output layers (encoded_dim will be the number o nodes)\n",
        "# encoder.add(tf.keras.layers.Dense(\n",
        "#     encoded_dim, use_bias=True, activation=\"linear\"\n",
        "# ))\n",
        "# # display the model\n",
        "# encoder.summary()"
      ],
      "metadata": {
        "id": "iw3HK5M2YVhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Unused # code 5.2- Implement decoder\n",
        "\n",
        "# #make an empty model\n",
        "# decoder = tf.keras.Sequential()\n",
        "# # Time-series by repeating input layer vectors to be able to add the later RNN(LSTM)\n",
        "# decoder.add(tf.keras.layers.RepeatVector(\n",
        "#     seq_length, input_dim=encoded_dim\n",
        "#   ))\n",
        "# # make LSTM layers and add them to the model\n",
        "# decoder.add(tf.keras.layers.LSTM(\n",
        "#     lstm_dim, use_bias=True, activation=\"tanh\",\n",
        "#     return_sequences=True\n",
        "#     ))\n",
        "\n",
        "# # add output layers to the model. The number of nodes should equal the input's\n",
        "# # return_sequncces is True because decoder is a time-series\n",
        "# # use softmax because the output is one-hot vectors on every time stamps\n",
        "# decoder.add(tf.keras.layers.Dense(\n",
        "#     input_dim, use_bias=True, activation=\"softmax\"\n",
        "#     ))\n",
        "# #display it\n",
        "# decoder.summary()"
      ],
      "metadata": {
        "id": "_opCxCEhanKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# keras.utils.plot_model(model, \"my_first_model.png\")"
      ],
      "metadata": {
        "id": "6WN3BhgNXlh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# keras.utils.plot_model(model, \"my_first_model_with_shape_info.png\", show_shapes=True)"
      ],
      "metadata": {
        "id": "LBmWtYReX7n8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Unused code\n",
        "# # code 4.3, prepare MIDI data for the model\n",
        "# # set the path for the MIDI file\n",
        "# dir = \"/content/drive/MyDrive/chorales/combined_notes2.mid\"\n",
        "\n",
        "# x_all = [] # the list which stores inputs of soprano melodies\n",
        "# y_all = [] # the list which stores outputs of alto melodies\n",
        "# keymodes = [] # the list which stores the key whether it is major or minor\n",
        "# files = [] # stores the filenames of the MIDI files\n",
        "\n",
        "# # repeat the process with all the midi files\n",
        "# for f in glob.glob(dir + \"/*.mid\"):\n",
        "#   print(f)\n",
        "#   try:\n",
        "#     # pr_s is for soprano pianoroll, pr_a is for alto, keymode is for either major 0 or minor 1\n",
        "#     # pr_s, pr_a, keymode = read_midi(f, True, 64)\n",
        "#     pr_s, pr_a, pr_b, keymode = read_midi(f, True, 64)\n",
        "#\n",
        "      # add rests to the pianoroll\n",
        "#     x = add_rest_nodes(pr_s)\n",
        "#     y = add_rest_nodes(pr_a)\n",
        "#\n",
        "      # x = add_rest_nodes(pr_b)\n",
        "#     # y = add_rest_nodes(pr_a)\n",
        "\n",
        "#     # add pianorolls which have been added rest elements to the lists\n",
        "#     x_all.append(x)\n",
        "#     y_all.append(y)\n",
        "#     keymodes.append(keymode)\n",
        "#     files.append(f)\n",
        "#   # throw exception for midi data which can not be  used\n",
        "#   except UnsupportedMidiFileException:\n",
        "#     print(\"skip\")\n",
        "# # convert x_all and y_all into NumPy array to make them more useful later\n",
        "# x_all = np.array(x_all)\n",
        "# y_all = np.array(y_all)"
      ],
      "metadata": {
        "id": "5KL-sgJ60h_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#failed Nov10th # oA_ Load the MIDI file and convert it to a numpy array\n",
        "# input_midi_path = '/content/drive/MyDrive/chorales/combined_notes2.mid'\n",
        "# input_mid = mido.MidiFile(input_midi_path, clip=True)\n",
        "\n",
        "# midi_data = []\n",
        "\n",
        "# for track in input_mid.tracks:\n",
        "#    for msg in track:\n",
        "#      if msg.type == 'note_on' or msg.type == 'note_off':\n",
        "#          # extract relevant information from the MIDI event\n",
        "#          time = msg.time\n",
        "#          note = msg.note\n",
        "#          velocity = msg.velocity\n",
        "#          # 1 for note_on, 0 for note_off\n",
        "#          event_type = 1 if msg.type == 'note_on' else 0\n",
        "\n",
        "#          # Append the information as a tuple to the MIDI data list\n",
        "#          midi_data.append((time, note, velocity, event_type))\n",
        "\n",
        "# # convert the MIDI data list to a numpy array\n",
        "# midi_data_array = np.array(midi_data)\n",
        "# print(midi_data_array)"
      ],
      "metadata": {
        "id": "ag12nuq8SWZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# failed code Nov 10th 2023\n",
        "\n",
        "# # Function to preprocess input for prediction\n",
        "# def preprocess_input(input_sequence, seq_length, input_dim):\n",
        "#     # Assuming input_sequence has shape (time_steps, features)\n",
        "\n",
        "#     # If input_dim is already correct, use it\n",
        "#     if input_sequence.shape[1] == input_dim:\n",
        "#         processed_input_sequence = input_sequence\n",
        "#     else:\n",
        "#         # Use only the first `input_dim` features\n",
        "#         processed_input_sequence = input_sequence[:, :input_dim]\n",
        "\n",
        "#     # If needed, pad or truncate the input sequence to match the expected sequence length\n",
        "#     if processed_input_sequence.shape[0] < seq_length:\n",
        "#         padding = np.zeros((seq_length - processed_input_sequence.shape[0], processed_input_sequence.shape[1]))\n",
        "#         processed_input_sequence = np.vstack((processed_input_sequence, padding))\n",
        "#     elif processed_input_sequence.shape[0] > seq_length:\n",
        "#         processed_input_sequence = processed_input_sequence[:seq_length, :]\n",
        "\n",
        "#     # Ensure the input sequence has the correct shape\n",
        "#     processed_input_sequence = np.reshape(processed_input_sequence, (1, seq_length, input_dim))\n",
        "\n",
        "#     return processed_input_sequence\n",
        "\n",
        "# # Function to post-process model output\n",
        "# def postprocess_output(output_sequence):\n",
        "#     # Assuming the output_sequence is in the shape (batch_size, seq_length, output_dim)\n",
        "#     # Extract the last time step of the output sequence\n",
        "#     last_time_step = output_sequence[:, -1, :]\n",
        "\n",
        "#     # Assuming the output_dim is the number of features in the output (e.g., note and velocity)\n",
        "#     output_dim = last_time_step.shape[1]\n",
        "\n",
        "#     # Reshape the last_time_step to (output_dim,)\n",
        "#     last_time_step = np.reshape(last_time_step, (output_dim,))\n",
        "\n",
        "#     # Denormalize the values if needed\n",
        "#     # For example, if notes were normalized to [0, 1], you might multiply them by 127 to get MIDI note values\n",
        "#     denormalized_notes = last_time_step[0] * 127.0  # Adjust this based on your normalization range\n",
        "#     denormalized_velocities = last_time_step[1] * 127.0  # Adjust this based on your normalization range\n",
        "\n",
        "#     # Assuming your output should be a tuple of (note, velocity)\n",
        "#     predicted_note = (denormalized_notes, denormalized_velocities)\n",
        "\n",
        "#     return predicted_note\n",
        "\n",
        "# # Generate the next note (Using the trained model)\n",
        "# def generate_next_note(model, input_sequence, seq_length, input_dim):\n",
        "#     # Preprocess input for prediction\n",
        "#     processed_input_sequence = preprocess_input(input_sequence, seq_length, input_dim)\n",
        "\n",
        "#     # Use the model to predict the next note\n",
        "#     next_note_sequence = model.predict(processed_input_sequence)\n",
        "\n",
        "#     # Post-process output to get the predicted note\n",
        "#     next_note = postprocess_output(next_note_sequence)\n",
        "\n",
        "#     return next_note\n",
        "\n",
        "# seq_length = 64  # Adjust this based on your model's expected sequence length\n",
        "# input_dim = 2  # Assuming you're using note and velocity as input features\n",
        "\n",
        "# # Assuming midi_data_array is your MIDI data in the format (time, note, velocity, event_type)\n",
        "# next_note = generate_next_note(model, midi_data_array, seq_length, input_dim)\n",
        "\n",
        "# print(next_note)\n"
      ],
      "metadata": {
        "id": "Nna0Bv81dObk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# failed attempt 1\n",
        "\n",
        "# # Extract the pitch of the first note from next_note\n",
        "# next_note_scalar = int(next_note[0][0][0])\n",
        "\n",
        "# # Create a PrettyMIDI object for the next note\n",
        "# output_midi = pretty_midi.PrettyMIDI()\n",
        "# instrument = pretty_midi.Instrument(0)\n",
        "\n",
        "# # Add the next note to the instrument\n",
        "# instrument.notes.append(pretty_midi.Note(\n",
        "#     velocity=64, pitch=next_note_scalar, start=0, end=1\n",
        "# ))\n",
        "\n",
        "# # Add the instrument to the MIDI file\n",
        "# output_midi.instruments.append(instrument)\n",
        "\n",
        "# # Save the generated note as a new MIDI file\n",
        "# output_midi.write(output_midi_path)\n"
      ],
      "metadata": {
        "id": "YHfE13TOVUTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# failed attempt 2\n",
        "\n",
        "# def generate_midi_from_notes(notes, output_path):\n",
        "#     # Create a PrettyMIDI object\n",
        "#     midi_data = pretty_midi.PrettyMIDI()\n",
        "\n",
        "#     # Create an Instrument instance for the generated notes\n",
        "#     instrument = pretty_midi.Instrument(0)\n",
        "\n",
        "#     time = 0  # Initialize the time\n",
        "\n",
        "#     # Iterate through the generated notes and create Note instances\n",
        "#     for step in range(len(notes)):\n",
        "#         for note_num, velocity in enumerate(notes[step]):\n",
        "#             if velocity.any() > 0: # to check if any value is greater than 0\n",
        "\n",
        "#                 # round the velocity to the nearest integer\n",
        "#                 velocity = np.round(velocity).astype(int)\n",
        "\n",
        "#                 # ensure the velocity is within the valid MIDI range(0-127)\n",
        "#                 velocity = np.maximum(0, np.minimum(velocity, 127))\n",
        "\n",
        "#                 # Create a Note instance for each active note\n",
        "#                 note = pretty_midi.Note(velocity=velocity, pitch=note_num, start=time, end=time+1/32)  # Adjust the duration as needed\n",
        "#                 instrument.notes.append(note)\n",
        "\n",
        "#         # Increment the time by one time step\n",
        "#         time += 1/32  # Adjust the time step as needed\n",
        "\n",
        "#     # Add the instrument to the MIDI object\n",
        "#     midi_data.instruments.append(instrument)\n",
        "\n",
        "#     # Write the MIDI data to a file\n",
        "#     print(output_path)\n",
        "#     midi_data.write(output_path)\n",
        "\n",
        "# # Generate the MIDI data from \"next_note\" and save it to a file\n",
        "# generate_midi_from_notes(next_note, output_midi_path)"
      ],
      "metadata": {
        "id": "0WNXDTXsX9br"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# failed attempt 3\n",
        "\n",
        "# def generate_midi_from_notes(notes, output_path):\n",
        "#     # Create a PrettyMIDI object\n",
        "#     midi_data = pretty_midi.PrettyMIDI()\n",
        "\n",
        "#     # Create an Instrument instance for the generated notes\n",
        "#     instrument = pretty_midi.Instrument(0)\n",
        "\n",
        "#     time = 0  # Initialize the time\n",
        "\n",
        "#     # Iterate through the generated notes and create Note instances\n",
        "#     for step in range(len(notes)):\n",
        "#         for note_num, velocity in enumerate(notes[step]):\n",
        "#             if np.any(velocity > 0):  # Use np.any() to check if any value is greater than zero\n",
        "#                 # Round the velocity to the nearest integer using np.round\n",
        "#                 velocity = np.round(velocity).astype(int)\n",
        "\n",
        "#                 # Ensure the velocity is within the valid MIDI range (0-127)\n",
        "#                 velocity = np.maximum(0, np.minimum(velocity, 127))\n",
        "\n",
        "#                 # Create a Note instance for each active note\n",
        "#                 note = pretty_midi.Note(velocity=velocity, pitch=note_num, start=time, end=time+1/32)  # Adjust the duration as needed\n",
        "#                 instrument.notes.append(note)\n",
        "\n",
        "#         # Increment the time by one time step\n",
        "#         time += 1/32  # Adjust the time step as needed\n",
        "\n",
        "#     # Add the instrument to the MIDI object\n",
        "#     midi_data.instruments.append(instrument)\n",
        "\n",
        "#     # Write the MIDI data to a file\n",
        "#     midi_data.write(output_path)\n"
      ],
      "metadata": {
        "id": "jyf6l6GbcpfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filed attempt 4\n",
        "\n",
        "# def generate_midi_from_notes(notes, output_path):\n",
        "#     # Create a PrettyMIDI object\n",
        "#     midi_data = pretty_midi.PrettyMIDI()\n",
        "\n",
        "#     # Create an Instrument instance for the generated notes\n",
        "#     instrument = pretty_midi.Instrument(0)\n",
        "\n",
        "#     time = 0  # Initialize the time\n",
        "\n",
        "#     # Define a function to convert values in the range [0, 1] to MIDI velocities (0-127)\n",
        "#     def velocity_to_midi(value):\n",
        "#         return int(value * 127)\n",
        "\n",
        "#     # Iterate through the generated notes and create Note instances\n",
        "#     for step in range(len(notes)):\n",
        "#         for note_num, velocity in enumerate(notes[step][0]):\n",
        "#             if velocity > 0:  # Check if the velocity is greater than 0\n",
        "#                 # Convert the value to MIDI velocity\n",
        "#                 midi_velocity = velocity_to_midi(velocity)\n",
        "\n",
        "#                 # Create a Note instance for each active note\n",
        "#                 note = pretty_midi.Note(velocity=midi_velocity, pitch=note_num, start=time, end=time+1/32)  # Adjust the duration as needed\n",
        "#                 instrument.notes.append(note)\n",
        "\n",
        "#         # Increment the time by one time step\n",
        "#         time += 1/32  # Adjust the time step as needed\n",
        "\n",
        "#     # Add the instrument to the MIDI object\n",
        "#     midi_data.instruments.append(instrument)\n",
        "\n",
        "#     # Write the MIDI data to a file\n",
        "#     midi_data.write(output_path)\n",
        "\n",
        "# generate_midi_from_notes(next_note, output_midi_path)\n"
      ],
      "metadata": {
        "id": "xQXT7yx0dXCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ambiguous function..\n",
        "\n",
        "# oA_ ATTENTION! You may want to modify this function if you want to generate only one single note\n",
        "# def create_sequence_from_midi(idi_data):\n",
        "#   notes = []\n",
        "#   for instrument in midi_data.instruments:\n",
        "#     for note in instrument.notes:\n",
        "#       notes.append((note.pitch, note.start))\n",
        "\n",
        "#   # Sort the notes by start time\n",
        "#   notes.sort(key=lambda x: x[1])\n",
        "\n",
        "#   # Create a list of time intervals between notes\n",
        "#   intervals = [notes[i+1][1] - notes[i][1] for i in range(len(notes)-1)]\n",
        "\n",
        "#   return intervals\n",
        "# note_intervals = create_sequence_from_midi(loaded_midi_data)"
      ],
      "metadata": {
        "id": "c9QI1y-fUopf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ambiguous function..\n",
        "\n",
        "# oA_ Load and preprocess the MIDI data\n",
        "# def load_midi(file_path):\n",
        "#   midi_data = pretty_midi.PrettyMIDI(file_path)\n",
        "#   return midi_data\n",
        "\n",
        "# loaded_midi_data = load_midi(input_midi_path)\n",
        "# print(loaded_midi_data)"
      ],
      "metadata": {
        "id": "Urt6CMQLT1Th"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}